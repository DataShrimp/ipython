{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入Atari撞球游戏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1132888d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"Breakout-v0\")\n",
    "s = env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "for i in range(200):\n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    a = env.action_space.sample()\n",
    "    s1, r, d, _ = env.step(a)\n",
    "    if d==True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "状态变量变为游戏图像，使用卷积神经网络建模，目标函数分解为对偶的状态优势和动作优势，使两者解耦，预测结果更鲁棒。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QNetwork:\n",
    "    def __init__(self, h_size):\n",
    "        # shape: N,100800\n",
    "        self.inputs = tf.placeholder(dtype=tf.float32, shape=[None, 210*160*3])\n",
    "        # N,210,160,3\n",
    "        imgs = tf.reshape(self.inputs, shape=[-1, 210, 160, 3])\n",
    "        # N,x1,y1,32\n",
    "        conv1 = tf.layers.conv2d(imgs, filters=32, kernel_size=8, strides=4, padding='VALID', bias_initializer=None)\n",
    "        # N,x2,y2,64\n",
    "        conv2 = tf.layers.conv2d(conv1, filters=64, kernel_size=4, strides=2, padding='VALID', bias_initializer=None)\n",
    "        # N,x3,y3,128\n",
    "        conv3 = tf.layers.conv2d(conv2, filters=128, kernel_size=2, strides=1, padding='VALID', bias_initializer=None)\n",
    "        # N,x4,y4,512\n",
    "        conv4 = tf.layers.conv2d(conv3, filters=h_size, kernel_size=1, strides=1, padding='VALID', bias_initializer=None)\n",
    "\n",
    "        # N,x4,y4,256, N,x4,y4,256\n",
    "        streamAC, streamVC = tf.split(conv4, 2, 3)\n",
    "        # N,x4*y4*256\n",
    "        streamA = tf.contrib.layers.flatten(streamAC)\n",
    "        streamV = tf.contrib.layers.flatten(streamVC)\n",
    "        # N,4(action_space.n)\n",
    "        A = tf.layers.dense(streamA, env.action_space.n, use_bias=False)\n",
    "        # N,1\n",
    "        V = tf.layers.dense(streamV, 1, use_bias=False)\n",
    "\n",
    "        # N,4\n",
    "        self.Qout = V + tf.subtract(A, tf.reduce_mean(A, axis=1, keep_dims=True))\n",
    "        # N,1\n",
    "        self.predict = tf.argmax(self.Qout, axis=1)\n",
    "\n",
    "        # N,1\n",
    "        self.targetQ = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "        # N,1\n",
    "        self.actions = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "        # N,4\n",
    "        actions_onehot = tf.one_hot(self.actions, env.action_space.n, dtype=tf.float32)\n",
    "\n",
    "        # N,1\n",
    "        Q = tf.reduce_sum(tf.multiply(self.Qout, actions_onehot), axis=1)\n",
    "        # 1\n",
    "        loss = tf.square(tf.reduce_sum(Q - self.targetQ))\n",
    "        optmize = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        self.update = optmize.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程，使用双向队列和随机采样实现\"经验回放\"，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 500 2.0 0.1\n",
      "2 1000 2.0 0.05\n",
      "5 1500 0.0 0.0333333333333\n",
      "6 2000 1.0 0.025\n",
      "7 2500 2.0 0.02\n",
      "10 3000 0.0 0.0166666666667\n",
      "12 3500 1.0 0.0142857142857\n",
      "13 4000 2.0 0.0125\n",
      "15 4500 0.0 0.0111111111111\n",
      "18 5000 0.0 0.01\n",
      "19 5000 0.0 0.00909090909091\n",
      "19 5000 0.0 0.00833333333333\n",
      "20 5000 0.0 0.00769230769231\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-119efbcc10ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mnewQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdiscount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mQN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mend_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 sess.run(mainQN.update, feed_dict={mainQN.inputs:np.stack(batch[:,0]), mainQN.targetQ:newQ,\n\u001b[0;32m---> 43\u001b[0;31m                                                    mainQN.actions:batch[:,1]})\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtotal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     sess.run(targetQN.update, feed_dict={targetQN.inputs:np.stack(batch[:,0]), \n",
      "\u001b[0;32m/Users/xu/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xu/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xu/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/xu/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xu/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "buff = deque(maxlen=5000)\n",
    "\n",
    "h_size = 512\n",
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(h_size)\n",
    "targetQN = QNetwork(h_size)\n",
    "\n",
    "num_episode = 1000\n",
    "num_exp = 1000\n",
    "e = 0.8\n",
    "total_step = 0\n",
    "batch_size = 32\n",
    "discount = 0.99\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episode):\n",
    "        s = env.reset()\n",
    "        s = np.reshape(s, -1)\n",
    "        rAll = 0\n",
    "        for j in range(num_exp):\n",
    "            if np.random.rand(1) < e:\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict, feed_dict={mainQN.inputs:[s]})[0]\n",
    "            s1, r, d, _ = env.step(a)\n",
    "            s1 = np.reshape(s1, -1)\n",
    "            buff.append(np.array([s,a,r,s1,d]))\n",
    "            s = s1\n",
    "            rAll += r\n",
    "            total_step += 1\n",
    "            \n",
    "            # update the Qnetwork\n",
    "            if total_step % 50 == 0:\n",
    "                batch = np.reshape(random.sample(buff, batch_size),[batch_size,5])\n",
    "                acts = sess.run(mainQN.predict, feed_dict={mainQN.inputs:np.stack(batch[:,3])})\n",
    "                QN = sess.run(targetQN.Qout, feed_dict={targetQN.inputs:np.stack(batch[:,3])})\n",
    "                end_token = -(batch[:,4]-1) # 游戏结束，负向惩罚\n",
    "                newQ = batch[:,2] + discount*QN[:,acts[0]]*end_token\n",
    "                sess.run(mainQN.update, feed_dict={mainQN.inputs:np.stack(batch[:,0]), mainQN.targetQ:newQ,\n",
    "                                                   mainQN.actions:batch[:,1]})\n",
    "                if total_step % 500 == 0:\n",
    "                    sess.run(targetQN.update, feed_dict={targetQN.inputs:np.stack(batch[:,0]), \n",
    "                                                         targetQN.targetQ:newQ, targetQN.actions:batch[:,1]})\n",
    "                    # show the precedure\n",
    "                    print i, rAll, e\n",
    "                # reduce the random probability\n",
    "                e = 1.0/((total_step/500)+1)\n",
    "            \n",
    "            if d==True:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
