{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入Atari撞球游戏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1132888d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"Breakout-v0\")\n",
    "s = env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "for i in range(200):\n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    a = env.action_space.sample()\n",
    "    s1, r, d, _ = env.step(a)\n",
    "    if d==True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1144f2ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "env = gameEnv(partial=False,size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "状态变量变为游戏图像，使用卷积神经网络建模，目标函数分解为对偶的状态优势和动作优势，使两者解耦，预测结果更鲁棒。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21168"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "84*84*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QNetwork:\n",
    "    def __init__(self, width, height, h_size, lr=0.0001, action_num=4, channel=3):\n",
    "        self.inputs = tf.placeholder(dtype=tf.float32, shape=[None, width*height*channel])\n",
    "        imgs = tf.reshape(self.inputs, shape=[-1, width, height, channel])\n",
    "        conv1 = tf.layers.conv2d(imgs, filters=32, kernel_size=8, strides=4, padding='VALID', bias_initializer=None)\n",
    "        conv2 = tf.layers.conv2d(conv1, filters=64, kernel_size=4, strides=2, padding='VALID', bias_initializer=None)\n",
    "        conv3 = tf.layers.conv2d(conv2, filters=64, kernel_size=3, strides=1, padding='VALID', bias_initializer=None)\n",
    "        conv4 = tf.layers.conv2d(conv3, filters=h_size, kernel_size=7, strides=1, padding='VALID', bias_initializer=None)\n",
    "\n",
    "        streamAC, streamVC = tf.split(conv4, 2, channel)\n",
    "        streamA = tf.contrib.layers.flatten(streamAC)\n",
    "        streamV = tf.contrib.layers.flatten(streamVC)\n",
    "        # N,4(action_space.n)\n",
    "        A = tf.layers.dense(streamA, action_num, use_bias=False)\n",
    "        # N,1\n",
    "        V = tf.layers.dense(streamV, 1, use_bias=False)\n",
    "\n",
    "        # N,4\n",
    "        self.Qout = V + tf.subtract(A, tf.reduce_mean(A, axis=1, keep_dims=True))\n",
    "        # N,1\n",
    "        self.predict = tf.argmax(self.Qout, axis=1)\n",
    "\n",
    "        # N,1\n",
    "        self.targetQ = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "        # N,1\n",
    "        self.actions = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "        # N,4\n",
    "        actions_onehot = tf.one_hot(self.actions, action_num, dtype=tf.float32)\n",
    "\n",
    "        # N,1\n",
    "        Q = tf.reduce_sum(tf.multiply(self.Qout, actions_onehot), axis=1)\n",
    "        # 1\n",
    "        loss = tf.reduce_mean(tf.square(Q - self.targetQ))\n",
    "        optmize = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "        self.update = optmize.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更新目标网络值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars, tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx, var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) +\n",
    "                                                          ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "        return op_holder\n",
    "\n",
    "def updateTarget(op_holder, sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程，使用双向队列和随机采样实现\"经验回放\"，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1.0 1.0\n",
      "50050 0.0 0.0999999999999\n",
      "100050 0.0 0.0999999999999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-2c92094a447f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0;31m# update network with target value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     sess.run(mainQN.update, feed_dict={mainQN.inputs:np.stack(batch[:,0]), mainQN.targetQ:targetQ,\n\u001b[0;32m---> 54\u001b[0;31m                                                        mainQN.actions:batch[:,1]})\n\u001b[0m\u001b[1;32m     55\u001b[0m                     \u001b[0;31m# udpate target network more slowly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtotal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mupdate_freq\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xu/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xu/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xu/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/xu/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xu/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "buff = deque(maxlen=50000)\n",
    "h_size = 512\n",
    "tar = 0.001\n",
    "\n",
    "num_episode = 10000\n",
    "num_exp = 50\n",
    "num_pre_train = 10000\n",
    "e = 1.0\n",
    "batch_size = 32\n",
    "discount = 0.99\n",
    "update_freq = 4\n",
    "path = \"./dqn\"\n",
    "load_model = False\n",
    "\n",
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(84, 84, h_size)\n",
    "targetQN = QNetwork(84, 84, h_size)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.saver()\n",
    "trainables = tf.trainable_variables()\n",
    "targetOps = updateTargetGraph(trainables, tau)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "total_step = 0\n",
    "r_list = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print(\"Loading model...\")\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episode):\n",
    "        local_buff = deque(maxlen=50000)\n",
    "        s = env.reset()\n",
    "        s = np.reshape(s, -1)\n",
    "        d = False\n",
    "        r_all = 0\n",
    "        for j in range(num_exp):\n",
    "            if np.random.rand(1) < e or total_step<num_pre_train:\n",
    "                #a = env.action_space.sample()\n",
    "                a = np.random.randint(0,env.actions)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict, feed_dict={mainQN.inputs:[s]})[0]\n",
    "            s1, r, d = env.step(a)\n",
    "            s1 = np.reshape(s1, -1)\n",
    "            local_buff.append(np.array([s,a,r,s1,d]))\n",
    "            total_step += 1\n",
    "            \n",
    "            # after pre train (randomness)\n",
    "            if total_step > num_pre_train:\n",
    "                # reduce the random probability\n",
    "                if e>0.1:\n",
    "                    e -= 0.9/10000\n",
    "            \n",
    "                # update the Qnetwork\n",
    "                if total_step % update_freq == 0:\n",
    "                    batch = np.reshape(random.sample(buff, batch_size),[batch_size,5])\n",
    "                    acts = sess.run(mainQN.predict, feed_dict={mainQN.inputs:np.vstack(batch[:,3])})\n",
    "                    QN = sess.run(targetQN.Qout, feed_dict={targetQN.inputs:np.vstack(batch[:,3])})\n",
    "                    end_token = -(batch[:,4]-1) # 游戏结束，负向惩罚\n",
    "                    doubleQ = QN[range(batch_size),acts]\n",
    "                    targetQ = batch[:,2] + discount*doubleQ*end_token\n",
    "                    # update network with target value\n",
    "                    sess.run(mainQN.update, feed_dict={mainQN.inputs:np.vstack(batch[:,0]), mainQN.targetQ:targetQ,\n",
    "                                                       mainQN.actions:batch[:,1]})\n",
    "                    updateTarget(targetOps, sess)\n",
    "                    # udpate target network more slowly\n",
    "                    #if total_step % (update_freq*1000) == 0:\n",
    "                    #    sess.run(targetQN.update, feed_dict={targetQN.inputs:np.stack(batch[:,0]), \n",
    "                    #                                         targetQN.targetQ:targetQ, targetQN.actions:batch[:,1]})\n",
    "            \n",
    "            s = s1\n",
    "            r_all += r\n",
    "            \n",
    "            if d==True:\n",
    "                break\n",
    "        buff.extend(local_buff)\n",
    "        r_list.append(r_all)\n",
    "        \n",
    "        # save model and show the precedure\n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess, path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"save model\")\n",
    "        if len(r_list)%10 == 0:\n",
    "            print(total_step, np.mean(r_list[-10:]), e)\n",
    "    saver.save(sess, path+'/model-'+str(i)+'.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
